# AdaptLab â€” Backend Architecture (End-to-End)

> How every request flows through the system, which modules talk to each other, and what math/AI drives the decisions.

---

## ðŸ—ï¸ System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Student    â”‚â”€â”€â”€â”€â–¶â”‚              FastAPI Server                  â”‚
â”‚   (Postman/  â”‚â—€â”€â”€â”€â”€â”‚              (main.py)                      â”‚
â”‚    Browser)  â”‚     â”‚                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
                    â”‚  â”‚ Submit   â”‚  â”‚ Problems â”‚  â”‚ Student  â”‚   â”‚
                    â”‚  â”‚ Router   â”‚  â”‚ Router   â”‚  â”‚ Router   â”‚   â”‚
                    â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚
                    â”‚       â”‚             â”‚             â”‚          â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚           Core Pipeline                â”‚  â”‚
                    â”‚  â”‚  Sandbox â”‚ Analysis â”‚ AI â”‚ DB          â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                    â”‚                                              â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
                    â”‚  â”‚  SQLite DB   â”‚    â”‚  Ollama (Local)  â”‚   â”‚
                    â”‚  â”‚  adaptlab.db â”‚    â”‚  Qwen 1.5B / 7B â”‚   â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“ Module Map

| Layer | Module | Role | Uses LLM? |
|-------|--------|------|-----------|
| **Entry** | `main.py` | FastAPI app, lifespan, router registration | âŒ |
| **API** | `api/routes_submit.py` | 10-step submission pipeline orchestrator | âŒ (calls AI modules) |
| **API** | `api/routes_problems.py` | Next problem & problem detail endpoints | âŒ |
| **API** | `api/routes_student.py` | Student profile, history, registration | âŒ |
| **API** | `api/routes_faculty.py` | Faculty dashboard, class overview, escalations | âŒ |
| **Sandbox** | `sandbox/executor.py` | Secure code execution with resource limits | âŒ |
| **Sandbox** | `sandbox/anti_gaming.py` | Hardcoding detection + rapid resubmit | âŒ |
| **Analysis** | `analysis/feature_extractor.py` | AST-based static code analysis | âŒ |
| **Analysis** | `analysis/capability_engine.py` | EMA capability score updates | âŒ |
| **Analysis** | `analysis/question_selector.py` | Zone-based / Gaussian problem selection | âŒ |
| **AI** | `ai/brain_a.py` | Quick feedback via Qwen 1.5B | âœ… |
| **AI** | `ai/brain_b.py` | Deep explanation via Qwen 7B | âœ… |
| **AI** | `ai/escalation.py` | Rule engine: when to call Brain B | âŒ |
| **AI** | `ai/validator.py` | Validates Brain B generated problems | âŒ |
| **DB** | `database/models.py` | 5 ORM tables (Student, Problem, Submission, CapabilityScore, EscalationLog) | âŒ |
| **DB** | `database/db.py` | SQLite connection, session factory, init | âŒ |
| **DB** | `database/seed.py` | 20 starter problems | âŒ |
| **Config** | `utils/constants.py` | All magic numbers in one place | âŒ |
| **Config** | `utils/logger.py` | Structured JSON logging | âŒ |
| **Schemas** | `schemas/*.py` | Pydantic request/response contracts | âŒ |

> **Key insight:** Only 2 out of 20 modules use an LLM. Everything else is deterministic.

---

## ðŸ”„ The 10-Step Submit Pipeline

When `POST /submit` is called, here's exactly what happens:

### Step 1 â€” Validate Student + Problem
```
routes_submit.py â†’ database/models.py
```
- Looks up `Student` by `student_id` â†’ 404 if not found
- Looks up `Problem` by `problem_id` â†’ 404 if not found or not validated
- Loads all test cases (visible + hidden) from the problem's JSON

### Step 2 â€” Anti-Gaming: Rapid Resubmit Check
```
routes_submit.py â†’ sandbox/anti_gaming.py â†’ check_rapid_resubmit()
```
- Queries last 5 submissions for this student+problem
- If same code submitted within 30 seconds â†’ **HTTP 429 cooldown**
- Prevents brute-force trial-and-error

### Step 3 â€” Execute Code in Sandbox
```
routes_submit.py â†’ sandbox/executor.py â†’ run_code()
```
- Writes student code to a temp `.py` file
- Syntax-checks via `py_compile`
- Runs against each test case in a **subprocess** with:
  - Timeout: 5 seconds per test case
  - Memory limit: 128MB (Linux only, skipped on Windows)
- Collects: `pass_rate`, `visible_pass_rate`, `hidden_pass_rate`, `stderr`
- **Hidden test results are NEVER exposed to the student**

### Step 4 â€” Anti-Gaming: Hardcoding Detection
```
routes_submit.py â†’ sandbox/anti_gaming.py â†’ check_hardcoding()
```
- Compares `visible_pass_rate` vs `hidden_pass_rate`
- If visible is 100% but hidden is 0% â†’ **hardcoding detected**
- If gap > 40% â†’ **suspicious gap**
- Penalty: effective pass_rate capped at **0.3**

### Step 5 â€” Extract Code Features (AST)
```
routes_submit.py â†’ analysis/feature_extractor.py â†’ extract_features()
```
- Parses code into an AST (Abstract Syntax Tree)
- Detects:
  - `uses_recursion`, `nested_loops`, `loop_count`
  - `complexity_estimate`: O(1) / O(n) / O(nÂ²) / O(n log n)
  - Error classification: `off_by_one`, `missing_base_case`, `wrong_data_structure`, `brute_force_detected`, `hardcoded_values`, `approach_mismatch`
- Returns a single `error_type` label (priority-ordered)
- **100% deterministic â€” no LLM**

### Step 6 â€” Brain A: Structured Feedback
```
routes_submit.py â†’ ai/brain_a.py â†’ get_feedback()
```
- Model: **Qwen2.5-Coder-1.5B** via Ollama
- Timeout: **3 seconds** (fast model, quick feedback)
- Input: problem statement, student code (truncated to 1500 chars), pass_rate, error_type, code features, visible test failures
- Output (strict JSON):
  - `feedback_text`: 1-2 sentences, no solution, no code, under 80 words
  - `mistake_category`: off_by_one | missing_base_case | brute_force | syntax | logic | ...
  - `difficulty_signal`: easier | same | harder
- **Failure policy**: If Ollama is down or JSON parse fails â†’ return safe defaults. **Never crashes.**

### Step 7 â€” Escalation Check
```
routes_submit.py â†’ ai/escalation.py â†’ check_escalation()
```
4 rules checked in priority order:

| # | Rule | Trigger | Example |
|---|------|---------|---------|
| 1 | `student_request` | `deep_explain: true` | Student clicks "explain more" |
| 2 | `streak` | 3+ consecutive failures on same concept | Stuck on recursion |
| 3 | `low_capability` | Capability score < 0.40 | Struggling badly |
| 4 | `conceptual_gap` | Compiled but < 50% pass rate, non-surface error | Understands syntax but not logic |

If any rule fires â†’ logged to `EscalationLog` table + Brain B is called.

### Step 8 â€” Brain B: Deep Explanation (Escalation Only)
```
routes_submit.py â†’ ai/brain_b.py â†’ get_deep_explanation()
```
- Model: **Qwen2.5-Coder-7B** via Ollama
- Timeout: **30 seconds** (larger model, more thorough)
- Only called when escalation triggers (saves compute)
- Output:
  - `explanation`: Detailed concept explanation
  - `step_by_step`: Guided solution steps (no direct code)
  - `alternative_approach`: A different way to think about it
  - `mini_problem`: A simpler practice problem (validated before storage)
- If mini_problem passes validation â†’ stored in the **problem bank** for future students

### Step 9 â€” Update Capability Scores (EMA)
```
routes_submit.py â†’ analysis/capability_engine.py â†’ update_capability()
```

**Math â€” Exponential Moving Average:**
```
new_score = (1 - weight) Ã— old_score + weight Ã— submission_score
```

- `submission_score` mapping:
  | Condition | Score |
  |-----------|-------|
  | Full pass (100%) | 1.0 |
  | Partial pass â‰¥ 50% | 0.6 |
  | Partial pass < 50% | 0.4 |
  | Zero pass | 0.3 |
  | Syntax error | 0.2 |
  | Timeout/crash | 0.1 |

- `weight` depends on the **error_type Ã— concept** combination:
  - `off_by_one` on `loops` â†’ weight = 0.20 (high impact)
  - `missing_base_case` on `recursion` â†’ weight = 0.20
  - Default weight = 0.15

- Score always clamped to **[0.0, 1.0]**

### Step 10 â€” Select Next Problem
```
routes_submit.py â†’ analysis/question_selector.py â†’ get_next_problem()
```

**Zone-Based Selection (default mode):**
```
Zone 0: score < 0.40  â†’ Too Difficult â†’ serve prerequisite concept
Zone 1: score < 0.55  â†’ Easy band
Zone 2: score < 0.75  â†’ Medium band (Learning Zone â€” optimal)
Zone 3: score â‰¥ 0.75  â†’ Hard band
```

- Brain A's `difficulty_signal` applies a **Â±1 band offset**:
  - "easier" â†’ band - 1
  - "same" â†’ band stays
  - "harder" â†’ band + 1
- If no problem in target band â†’ falls back to band - 1
- **NEVER serves the same problem twice** to the same student

**Gaussian Selection (advanced mode, off by default):**
```
U(q | Ï€â‚›) = exp(-(sâ‚› - Î¼)Â² / (2ÏƒÂ²))
```
- Scores every available problem by how close its difficulty matches the student's frontier
- Î¼ = 0.5 (optimal challenge point), Ïƒ = 0.2 (tolerance band)

### Final â€” Persist & Respond
- The `Submission` row is saved with all data (code, pass_rate, feedback, escalation, gaming flags)
- Everything committed in a single DB transaction
- Full `SubmitResponse` returned to the client

---

## ðŸ—„ï¸ Database Schema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   students   â”‚     â”‚   problems   â”‚     â”‚   submissions    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ student_id   â”‚â—„â”€â”€â”€â”€â”‚              â”‚â—„â”€â”€â”€â”€â”‚ submission_id    â”‚
â”‚ name         â”‚     â”‚ problem_id   â”‚     â”‚ student_id (FK)  â”‚
â”‚ email        â”‚     â”‚ title        â”‚     â”‚ problem_id (FK)  â”‚
â”‚ created_at   â”‚     â”‚ statement    â”‚     â”‚ code             â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ concept_tags â”‚     â”‚ pass_rate        â”‚
       â”‚             â”‚ difficulty   â”‚     â”‚ error_type       â”‚
       â”‚             â”‚ test_cases   â”‚     â”‚ brain_a_feedback â”‚
       â”‚             â”‚ hidden_ratio â”‚     â”‚ brain_b_feedback â”‚
       â”‚             â”‚ validated    â”‚     â”‚ escalated        â”‚
       â”‚             â”‚ created_by   â”‚     â”‚ gaming_flagged   â”‚
       â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ capability_scoresâ”‚     â”‚ escalation_logs  â”‚
       â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
       â”‚         â”‚ student_id (FK)  â”‚     â”‚ log_id           â”‚
       â”‚         â”‚ concept          â”‚     â”‚ student_id (FK)  â”‚
       â”‚         â”‚ score            â”‚     â”‚ problem_id (FK)  â”‚
       â”‚         â”‚ updated_at       â”‚     â”‚ submission_id(FK)â”‚
       â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ reason           â”‚
       â”‚                                  â”‚ resolved         â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ logged_at        â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ” Safety & Invariants

These rules are **enforced in code** and never violated:

1. **Hidden test cases are NEVER exposed** â€” not in responses, not in errors
2. **Brain A's `difficulty_signal` NEVER writes to capability scores** â€” it only biases question routing
3. **Same problem is NEVER served twice** to the same student
4. **Brain B mini-problems are ALWAYS validated** before entering the problem bank
5. **All LLM calls have safe defaults** â€” system NEVER crashes if Ollama is down
6. **Capability scores are always in [0.0, 1.0]** â€” clamped after every update
7. **Anti-gaming is checked BEFORE and AFTER execution** â€” two separate checks
8. **Escalation logs are immutable** â€” once written, can only be marked resolved

---

## ðŸš€ How to Run

```bash
cd adaptlab
pip install -r requirements.txt
python main.py
# Server starts on http://localhost:8000
# Swagger docs at http://localhost:8000/docs
```

For full LLM support, start Ollama with:
```bash
ollama pull qwen2.5-coder:1.5b
ollama pull qwen2.5-coder:7b
ollama serve
```
